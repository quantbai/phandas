import requests
import pandas as pd
import sqlite3
from datetime import datetime, timedelta
import time
import logging
import pytz
from typing import Dict, List
from web3 import Web3

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('dai_onchain.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DAIOnChainScraper:
    def __init__(self, db_path='dai_stablecoin.db'):
        self.db_path = db_path
        
        # EVMéˆé…ç½®
        self.chains_config = {
            'ethereum': {
                'name': 'Ethereum',
                'rpc': 'https://eth-mainnet.g.alchemy.com/v2/demo',
                'dai_contract': '0x6b175474e89094c44da98b954eedeac495271d0f',
                'block_time': 12,
                'code': 'ETH'
            },
            'arbitrum': {
                'name': 'Arbitrum',
                'rpc': 'https://arb-mainnet.g.alchemy.com/v2/demo',
                'dai_contract': '0xda10009cbd5d07dd0cecc66161fc93d7c9000da1',
                'block_time': 0.25,
                'code': 'ARB'
            },
            'optimism': {
                'name': 'OP Mainnet',
                'rpc': 'https://opt-mainnet.g.alchemy.com/v2/demo',
                'dai_contract': '0xda10009cbd5d07dd0cecc66161fc93d7c9000da1',
                'block_time': 2,
                'code': 'OP'
            },
            'bsc': {
                'name': 'BSC',
                'rpc': 'https://bsc-dataseed.binance.org',
                'dai_contract': '0x1af3f329e8be154074d8769d1ffa4ee058b1dbc3',
                'block_time': 3,
                'code': 'BNB'
            },
            'polygon': {
                'name': 'Polygon',
                'rpc': 'https://polygon-rpc.com',
                'dai_contract': '0x8f3cf7ad23cd3cadbd9735aff958023239c6a063',
                'block_time': 2,
                'code': 'POL'
            },
            'base': {
                'name': 'Base',
                'rpc': 'https://mainnet.base.org',
                'dai_contract': '0x50c5725949a6f0c72e6c4a641f24049a917db0cb',
                'block_time': 2,
                'code': 'BASE'
            }
        }
        
        # Solanaé…ç½®
        self.solana_config = {
            'name': 'Solana',
            'rpc': 'https://api.mainnet-beta.solana.com',
            'code': 'SOL',
            'dai_mint': 'FYpdBuyAHSbdaAyD1sKkxyLWbAP8uUW9h6uvdhK74ij1'
        }
        
        # ERC20 ABI
        self.erc20_abi = [
            {
                "constant": True,
                "inputs": [],
                "name": "totalSupply",
                "outputs": [{"name": "", "type": "uint256"}],
                "type": "function"
            },
            {
                "constant": True,
                "inputs": [],
                "name": "decimals",
                "outputs": [{"name": "", "type": "uint8"}],
                "type": "function"
            }
        ]
        
        self.init_database()
    
    def init_database(self):
        """åˆå§‹åŒ–æ•¸æ“šåº«"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS dai_supply (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME NOT NULL,
                chain TEXT NOT NULL,
                dai_amount REAL NOT NULL,
                block_number INTEGER,
                source TEXT DEFAULT 'onchain_rpc',
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(timestamp, chain)
            )
        ''')
        conn.commit()
        conn.close()
        
        import os
        db_path_absolute = os.path.abspath(self.db_path)
        logger.info(f"âœ“ æ•¸æ“šåº«åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"  æ•¸æ“šåº«ä½ç½®: {db_path_absolute}")
    
    def get_current_block(self, chain_key: str, max_retries: int = 3) -> int:
        """ç²å–ç•¶å‰å€å¡Šè™Ÿï¼ˆå¸¶é‡è©¦æ©Ÿåˆ¶ï¼‰"""
        config = self.chains_config[chain_key]
        
        for attempt in range(max_retries):
            try:
                w3 = Web3(Web3.HTTPProvider(config['rpc'], request_kwargs={"timeout": 10}))
                
                if not w3.is_connected():
                    if attempt < max_retries - 1:
                        wait_time = 2 ** attempt
                        logger.warning(f"âš ï¸  {config['name']} é€£æ¥å¤±æ•—ï¼Œ{wait_time}ç§’å¾Œé‡è©¦... ({attempt+1}/{max_retries})")
                        time.sleep(wait_time)
                        continue
                    else:
                        logger.error(f"âŒ ç„¡æ³•é€£æ¥ {config['name']} RPC (å·²é‡è©¦{max_retries}æ¬¡)")
                        return None
                
                block_num = w3.eth.block_number
                logger.debug(f"  {config['name']}: ç•¶å‰å€å¡Šè™Ÿ {block_num}")
                return block_num
            
            except Exception as e:
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt
                    logger.warning(f"âš ï¸  {config['name']} æŸ¥è©¢å€å¡Šå¤±æ•—ï¼Œ{wait_time}ç§’å¾Œé‡è©¦... ({attempt+1}/{max_retries})")
                    logger.debug(f"    éŒ¯èª¤: {e}")
                    time.sleep(wait_time)
                else:
                    logger.error(f"âŒ {config['name']} ç„¡æ³•ç²å–å€å¡Š (å·²é‡è©¦{max_retries}æ¬¡)")
                    return None
        
        return None
    
    def estimate_block_number(self, chain_key: str, target_timestamp: int, current_block: int) -> int:
        """æ ¹æ“šæ™‚é–“æˆ³ä¼°ç®—å°æ‡‰çš„å€å¡Šè™Ÿ"""
        try:
            config = self.chains_config[chain_key]
            w3 = Web3(Web3.HTTPProvider(config['rpc']))
            
            current_block_data = w3.eth.get_block(current_block)
            current_timestamp = current_block_data['timestamp']
            
            time_diff = current_timestamp - target_timestamp
            block_diff = int(time_diff / config['block_time'])
            estimated_block = current_block - block_diff
            
            estimated_block = max(0, estimated_block)
            return estimated_block
        
        except Exception as e:
            logger.warning(f"ä¼°ç®— {chain_key} å€å¡Šè™Ÿå¤±æ•—: {e}")
            return None
    
    def query_total_supply(self, chain_key: str, block_number: int, max_retries: int = 3) -> float:
        """æŸ¥è©¢ç‰¹å®šå€å¡Šçš„DAI totalSupplyï¼ˆå¸¶é‡è©¦æ©Ÿåˆ¶ï¼‰"""
        config = self.chains_config[chain_key]
        
        for attempt in range(max_retries):
            try:
                w3 = Web3(Web3.HTTPProvider(config['rpc'], request_kwargs={"timeout": 10}))
                
                if not w3.is_connected():
                    if attempt < max_retries - 1:
                        wait_time = 2 ** attempt
                        logger.debug(f"  {config['name']} é€£æ¥å¤±æ•—ï¼Œ{wait_time}ç§’å¾Œé‡è©¦...")
                        time.sleep(wait_time)
                        continue
                    else:
                        return None
                
                contract_address = Web3.to_checksum_address(config['dai_contract'])
                contract = w3.eth.contract(
                    address=contract_address,
                    abi=self.erc20_abi
                )
                
                total_supply_raw = contract.functions.totalSupply().call(block_identifier=block_number)
                decimals = contract.functions.decimals().call(block_identifier=block_number)
                total_supply = total_supply_raw / (10 ** decimals)
                
                return total_supply
            
            except Exception as e:
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt
                    logger.debug(f"  {config['name']} æŸ¥è©¢å¤±æ•—ï¼Œ{wait_time}ç§’å¾Œé‡è©¦... ({attempt+1}/{max_retries})")
                    time.sleep(wait_time)
                else:
                    logger.warning(f"æŸ¥è©¢ {chain_key} å€å¡Š {block_number} çš„totalSupplyå¤±æ•— (å·²é‡è©¦{max_retries}æ¬¡)")
                    return None
        
        return None
    
    def fetch_historical_data(self, chain_key: str, days: int = 730) -> List[Dict]:
        """æ¯å¤©æ›´æ–°ä¸€æ¬¡DAIä¾›æ‡‰é‡å¿«ç…§"""
        if chain_key == 'solana':
            return self.fetch_solana_snapshot()
        
        config = self.chains_config[chain_key]
        logger.info(f"\nã€{config['name']}ã€‘æŸ¥è©¢ç•¶å‰DAIä¾›æ‡‰é‡...")
        
        all_data = []
        
        try:
            current_block = self.get_current_block(chain_key)
            if current_block is None:
                logger.error(f"âŒ {config['name']} ç„¡æ³•ç²å–ç•¶å‰å€å¡Š")
                return []
            
            total_supply = self.query_total_supply(chain_key, current_block)
            
            if total_supply is not None:
                all_data.append({
                    'timestamp': datetime.now(pytz.UTC),
                    'chain': config['code'],
                    'dai_amount': total_supply,
                    'block_number': current_block,
                    'source': 'onchain_rpc'
                })
                
                logger.info(f"  {config['code']}: {total_supply:,.0f} DAI @ å€å¡Š {current_block}")
            else:
                logger.warning(f"  {config['code']}: æŸ¥è©¢å¤±æ•—")
            
        except Exception as e:
            logger.error(f"æŸ¥è©¢ {chain_key} å¤±æ•—: {e}")
        
        return all_data
    
    def fetch_historical_data_init(self, chain_key: str, days: int = 730, interval: int = 1) -> List[Dict]:
        """ã€é¦–æ¬¡åˆå§‹åŒ–ç”¨ã€‘çˆ¬å–éå»Nå¤©çš„DAIæ­·å²ï¼ˆå¯èª¿æ•´é–“éš”ï¼‰"""
        if chain_key == 'solana':
            return self.fetch_solana_snapshot()
        
        config = self.chains_config[chain_key]
        logger.info(f"\nã€{config['name']}ã€‘çˆ¬å–éå»{days}å¤©çš„æ­·å²æ•¸æ“šï¼ˆé–“éš”{interval}å¤©ï¼‰...")
        
        current_block = self.get_current_block(chain_key)
        if current_block is None:
            logger.error(f"âŒ {config['name']} ç„¡æ³•ç²å–ç•¶å‰å€å¡Š")
            return []
        
        end_date = datetime.now(pytz.UTC)
        all_data = []
        failed_days = []
        
        day_offsets = list(range(0, days, interval))
        day_offsets.append(days - 1)
        day_offsets = sorted(set(day_offsets), reverse=True)
        
        for idx, day_offset in enumerate(day_offsets):
            target_date = end_date - timedelta(days=day_offset)
            target_timestamp = int(target_date.timestamp())
            
            estimated_block = self.estimate_block_number(
                chain_key, target_timestamp, current_block
            )
            
            if estimated_block is None:
                failed_days.append(day_offset)
                continue
            
            total_supply = None
            max_retries = 3
            for retry in range(max_retries):
                try:
                    total_supply = self.query_total_supply(chain_key, estimated_block)
                    if total_supply is not None:
                        break
                except Exception as e:
                    if retry < max_retries - 1:
                        wait_time = 2 ** retry
                        logger.debug(f"  {config['name']} é‡è©¦ ({retry+1}/{max_retries})...")
                        time.sleep(wait_time)
                    else:
                        failed_days.append(day_offset)
            
            if total_supply is not None:
                all_data.append({
                    'timestamp': target_date,
                    'chain': config['code'],
                    'dai_amount': total_supply,
                    'block_number': estimated_block,
                    'source': 'onchain_rpc_historical'
                })
                
                logger.info(f"  {target_date.date()}: {total_supply:,.0f} DAI")
            
            if (idx + 1) % 5 == 0:
                logger.info(f"  é€²åº¦: {idx + 1}/{len(day_offsets)}")
                time.sleep(1)
        
        success_count = len(all_data)
        logger.info(f"âœ“ {config['name']} ç²å–åˆ° {success_count} å€‹æ™‚é–“é»çš„æ•¸æ“š")
        
        if failed_days:
            logger.warning(f"  âš ï¸ å¤±æ•—äº† {len(failed_days)} å€‹æ™‚é–“é»")
        
        return all_data
    
    def fetch_solana_snapshot(self) -> List[Dict]:
        """æŸ¥è©¢Solanaç•¶å‰DAIä¾›æ‡‰é‡å¿«ç…§"""
        if not self.solana_config.get('dai_mint'):
            logger.warning("âŒ Solana: æœªé…ç½®DAI mint address")
            logger.info("   æç¤ºï¼šå¦‚æœçŸ¥é“å®˜æ–¹mint addressï¼Œè«‹å‘Šè¨´æˆ‘æˆ–åœ¨ä»£ç¢¼ä¸­é…ç½®")
            return []
        
        logger.info(f"\nã€Solanaã€‘æŸ¥è©¢ç•¶å‰DAIä¾›æ‡‰é‡...")
        
        all_data = []
        
        try:
            supply = self.query_solana_dai_supply()
            if supply is not None:
                all_data.append({
                    'timestamp': datetime.now(pytz.UTC),
                    'chain': self.solana_config['code'],
                    'dai_amount': supply,
                    'block_number': None,
                    'source': 'solana_rpc'
                })
                logger.info(f"  SOL: {supply:,.0f} DAI")
            else:
                logger.warning(f"  SOL: ç„¡æ³•ç²å–DAIä¾›æ‡‰é‡ï¼ˆmint addresså¯èƒ½éŒ¯èª¤ï¼‰")
        except Exception as e:
            logger.error(f"  SolanaæŸ¥è©¢å¤±æ•—: {e}")
        
        return all_data
    
    def query_solana_dai_supply(self, max_retries: int = 3) -> float:
        """æŸ¥è©¢Solanaä¸ŠDAIçš„ç•¶å‰ä¾›æ‡‰é‡ï¼ˆå¸¶é‡è©¦æ©Ÿåˆ¶ï¼‰"""
        for attempt in range(max_retries):
            try:
                payload = {
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": "getTokenSupply",
                    "params": [self.solana_config['dai_mint']]
                }
                
                response = requests.post(
                    self.solana_config['rpc'],
                    json=payload,
                    timeout=10
                )
                response.raise_for_status()
                
                data = response.json()
                
                if 'result' in data and data['result']:
                    supply_raw = int(data['result']['value']['amount'])
                    decimals = int(data['result']['value']['decimals'])
                    total_supply = supply_raw / (10 ** decimals)
                    return total_supply
                else:
                    error_msg = data.get('error', 'ç„¡è¿”å›æ•¸æ“š')
                    if attempt < max_retries - 1:
                        wait_time = 2 ** attempt
                        logger.debug(f"  Solana è¿”å›éŒ¯èª¤ï¼Œ{wait_time}ç§’å¾Œé‡è©¦... ({attempt+1}/{max_retries})")
                        time.sleep(wait_time)
                    else:
                        logger.warning(f"  Solana: {error_msg} (å·²é‡è©¦{max_retries}æ¬¡)")
                    continue
            
            except requests.exceptions.Timeout:
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt
                    logger.debug(f"  Solana è¶…æ™‚ï¼Œ{wait_time}ç§’å¾Œé‡è©¦... ({attempt+1}/{max_retries})")
                    time.sleep(wait_time)
                else:
                    logger.error(f"  SolanaæŸ¥è©¢è¶…æ™‚ (å·²é‡è©¦{max_retries}æ¬¡)")
            
            except Exception as e:
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt
                    logger.debug(f"  Solana æŸ¥è©¢ç•°å¸¸ï¼Œ{wait_time}ç§’å¾Œé‡è©¦... ({attempt+1}/{max_retries})")
                    time.sleep(wait_time)
                else:
                    logger.error(f"  SolanaæŸ¥è©¢ç•°å¸¸ (å·²é‡è©¦{max_retries}æ¬¡): {e}")
        
        return None
    
    def fetch_current_data(self) -> List[Dict]:
        """ç²å–æ‰€æœ‰éˆçš„ç•¶å‰DAIä¾›æ‡‰é‡"""
        logger.info(f"\nã€å¯¦æ™‚æ›´æ–°ã€‘æŸ¥è©¢æ‰€æœ‰éˆçš„ç•¶å‰DAIä¾›æ‡‰é‡...")
        all_data = []
        
        for chain_key, config in self.chains_config.items():
            try:
                current_block = self.get_current_block(chain_key)
                if current_block is None:
                    continue
                
                total_supply = self.query_total_supply(chain_key, current_block)
                
                if total_supply is not None:
                    all_data.append({
                        'timestamp': datetime.now(pytz.UTC),
                        'chain': config['code'],
                        'dai_amount': total_supply,
                        'block_number': current_block,
                        'source': 'onchain_rpc'
                    })
                    
                    logger.info(f"  {config['code']:5}: {total_supply:>20,.0f} DAI @ å€å¡Š {current_block}")
                
                time.sleep(0.5)
            
            except Exception as e:
                logger.error(f"æŸ¥è©¢ {chain_key} å¤±æ•—: {e}")
                continue
        
        try:
            if self.solana_config.get('dai_mint'):
                logger.info(f"  æŸ¥è©¢ Solana...")
                supply = self.query_solana_dai_supply()
                if supply is not None:
                    all_data.append({
                        'timestamp': datetime.now(pytz.UTC),
                        'chain': self.solana_config['code'],
                        'dai_amount': supply,
                        'block_number': None,
                        'source': 'solana_rpc'
                    })
                    logger.info(f"  SOL : {supply:>20,.0f} DAI")
                else:
                    logger.warning(f"  SOL : ç„¡æ³•ç²å–ï¼ˆmint addresså¯èƒ½éŒ¯èª¤æˆ–DAIæœªéƒ¨ç½²ï¼‰")
            else:
                logger.warning(f"  SOL : æœªé…ç½®DAI mint address")
            time.sleep(0.5)
        except Exception as e:
            logger.warning(f"SolanaæŸ¥è©¢å¤±æ•—: {e}")
        
        return all_data
    
    def save_to_database(self, data_list: List[Dict]) -> int:
        """ä¿å­˜æ•¸æ“šåˆ°æ•¸æ“šåº«"""
        if not data_list:
            logger.warning("æ²’æœ‰æ•¸æ“šå¯ä¿å­˜")
            return 0
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        saved_count = 0
        
        try:
            for record in data_list:
                cursor.execute('''
                    INSERT OR IGNORE INTO dai_supply 
                    (timestamp, chain, dai_amount, block_number, source)
                    VALUES (?, ?, ?, ?, ?)
                ''', (
                    record['timestamp'].isoformat(),
                    record['chain'],
                    record['dai_amount'],
                    record.get('block_number'),
                    record.get('source', 'onchain_rpc')
                ))
                saved_count += cursor.rowcount
            
            conn.commit()
            logger.info(f"âœ“ ä¿å­˜ {saved_count} ç­†æ–°æ•¸æ“šåˆ°æ•¸æ“šåº«")
            return saved_count
        
        except Exception as e:
            logger.error(f"ä¿å­˜æ•¸æ“šå¤±æ•—: {e}")
            conn.rollback()
        finally:
            conn.close()
        
        return saved_count
    
    def get_dataframe(self, start_date=None, end_date=None, chain=None):
        """è®€å–æ•¸æ“šç‚ºDataFrame"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            query = "SELECT timestamp, chain, dai_amount, block_number FROM dai_supply WHERE 1=1"
            params = []
            
            if start_date:
                query += " AND timestamp >= ?"
                params.append(start_date.isoformat() if isinstance(start_date, datetime) else start_date)
            
            if end_date:
                query += " AND timestamp <= ?"
                params.append(end_date.isoformat() if isinstance(end_date, datetime) else end_date)
            
            if chain:
                query += " AND chain = ?"
                params.append(chain)
            
            query += " ORDER BY timestamp ASC"
            
            df = pd.read_sql_query(query, conn, params=params)
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            conn.close()
            
            return df
        
        except Exception as e:
            logger.error(f"è®€å–æ•¸æ“šå¤±æ•—: {e}")
            return pd.DataFrame()
    
    def run_full_scrape(self, days=730):
        """æ¯æ—¥å¿«ç…§æ›´æ–°"""
        print("\n" + "="*70)
        print("DAI æ¯æ—¥å¿«ç…§æ›´æ–°ï¼ˆEVMéˆ + Solanaï¼‰")
        print("="*70)
        
        all_data = []
        
        print(f"\nã€æ­£åœ¨æ›´æ–°ã€‘æŸ¥è©¢æ‰€æœ‰éˆç•¶å‰DAIä¾›æ‡‰é‡...")
        
        for chain_key in list(self.chains_config.keys()):
            chain_data = self.fetch_historical_data(chain_key, days=days)
            all_data.extend(chain_data)
            time.sleep(0.5)
        
        solana_data = self.fetch_historical_data('solana', days=days)
        all_data.extend(solana_data)
        time.sleep(0.5)
        
        if all_data:
            self.save_to_database(all_data)
        
        print("\n" + "="*70)
        print("æ›´æ–°å®Œæˆ - æ•¸æ“šçµ±è¨ˆ")
        print("="*70)
        
        df = self.get_dataframe()
        if not df.empty:
            print(f"\nâœ“ æ•¸æ“šåº«å…± {len(df)} ç­†è¨˜éŒ„")
            print(f"  æ™‚é–“ç¯„åœ: {df['timestamp'].min()} è‡³ {df['timestamp'].max()}")
            print(f"  æ•¸æ“šè¦†è“‹: ç´„ {(df['timestamp'].max() - df['timestamp'].min()).days} å¤©")
            print(f"\næŒ‰éˆçµ±è¨ˆ:")
            print(df['chain'].value_counts().to_string())
            
            print(f"\næœ€æ–°å¿«ç…§:")
            latest = df[df['timestamp'] == df['timestamp'].max()]
            for _, row in latest.iterrows():
                print(f"  {row['chain']:5}: {row['dai_amount']:>20,.0f} DAI")
        
        print("\n" + "="*70)
    
    def run_initial_scrape(self, days=730):
        """ã€é¦–æ¬¡åˆå§‹åŒ–ç”¨ã€‘çˆ¬å–éå»2å¹´çš„æ­·å²æ•¸æ“š"""
        print("\n" + "="*70)
        print("DAI æ­·å²æ•¸æ“šåˆå§‹åŒ–ï¼ˆé¦–æ¬¡é‹è¡Œç”¨ï¼‰")
        print("="*70)
        print(f"\nçˆ¬å–éå» {days} å¤©ï¼ˆ{days//365} å¹´ï¼‰çš„æ­·å²æ•¸æ“š...")
        print("æ¯10å¤©æŸ¥è©¢ä¸€æ¬¡ï¼ˆåŠ å¿«é€Ÿåº¦ï¼‰")
        
        all_data = []
        
        for chain_key in list(self.chains_config.keys()):
            chain_data = self.fetch_historical_data_init(chain_key, days=days)
            all_data.extend(chain_data)
            time.sleep(2)
        
        solana_data = self.fetch_historical_data('solana', days=days)
        all_data.extend(solana_data)
        time.sleep(2)
        
        if all_data:
            self.save_to_database(all_data)
        
        print("\n" + "="*70)
        print("åˆå§‹åŒ–å®Œæˆ - æ•¸æ“šçµ±è¨ˆ")
        print("="*70)
        
        df = self.get_dataframe()
        if not df.empty:
            print(f"\nâœ“ æ•¸æ“šåº«å…± {len(df)} ç­†è¨˜éŒ„")
            print(f"  æ™‚é–“ç¯„åœ: {df['timestamp'].min()} è‡³ {df['timestamp'].max()}")
            print(f"  æ•¸æ“šè¦†è“‹: ç´„ {(df['timestamp'].max() - df['timestamp'].min()).days} å¤©")
            print(f"\næŒ‰éˆçµ±è¨ˆ:")
            print(df['chain'].value_counts().to_string())
            
            print(f"\næœ€æ–°å¿«ç…§:")
            latest = df[df['timestamp'] == df['timestamp'].max()]
            for _, row in latest.iterrows():
                print(f"  {row['chain']:5}: {row['dai_amount']:>20,.0f} DAI")
        
        print("\n" + "="*70)
        print("\nâœ… åˆå§‹åŒ–å®Œæˆï¼")
        print("ä¹‹å¾Œæ¯å¤©é‹è¡Œæ­¤è…³æœ¬æ™‚ï¼Œæ”¹ç‚ºèª¿ç”¨ scraper.run_full_scrape()")
        print("="*70)


if __name__ == "__main__":
    import os
    
    db_path = 'dai_stablecoin.db'
    scraper = DAIOnChainScraper()
    
    # æª¢æŸ¥æ˜¯å¦æ˜¯é¦–æ¬¡é‹è¡Œ
    is_first_run = not os.path.exists(db_path)
    
    print("\n" + "="*70)
    print("DAI æ¯æ—¥å¿«ç…§çˆ¬èŸ² - å•Ÿå‹•")
    print("="*70)
    
    if is_first_run:
        # é¦–æ¬¡é‹è¡Œæ™‚æç¤º
        print("\nğŸ” æª¢æ¸¬çµæœ: é¦–æ¬¡é‹è¡Œï¼ˆæ•¸æ“šåº«ä¸å­˜åœ¨ï¼‰")
        print("\nå°‡åŸ·è¡Œã€æ­·å²æ•¸æ“šåˆå§‹åŒ–ã€‘è£œå……éå»2å¹´çš„æ•¸æ“š")
        print("é è¨ˆè€—æ™‚: 2-3 å°æ™‚")
        print("ğŸ’¡ æç¤º: ä¸­é€”å¯æŒ‰ Ctrl+C æš«åœï¼Œä¸‹æ¬¡é‹è¡Œæœƒè‡ªå‹•æ¢å¾©")
        print("\n" + "="*70)
        
        confirm = input("\nç¢ºèªé–‹å§‹åˆå§‹åŒ–? (yes/no): ").strip().lower()
        if confirm != 'yes':
            print("âŒ å·²å–æ¶ˆåˆå§‹åŒ–ï¼Œé€€å‡ºç¨‹å¼")
            exit(0)
        
        scraper.run_initial_scrape(days=730)
        
        print("\n" + "="*70)
        print("âœ… åˆå§‹åŒ–å®Œæˆï¼")
        print("\nä¹‹å¾Œé‹è¡Œæ­¤è…³æœ¬å°‡è‡ªå‹•é€²å…¥ã€æ¯æ—¥æ›´æ–°æ¨¡å¼ã€‘")
        print("æ¯å¤©é‹è¡Œä¸€æ¬¡å³å¯è‡ªå‹•ç´¯ç©æ­·å²æ•¸æ“š")
        print("="*70)
    
    else:
        # éé¦–æ¬¡é‹è¡Œï¼šæª¢æŸ¥æ˜¯å¦éœ€è¦è£œå……æ­·å²æ•¸æ“š
        df = scraper.get_dataframe()
        record_count = len(df)
        
        print(f"\nğŸ” æª¢æ¸¬åˆ°æ—¢æœ‰æ•¸æ“šåº«")
        print(f"  ç•¶å‰è¨˜éŒ„æ•¸: {record_count} ç­†")
        
        need_init = False
        if df.empty:
            print(f"  âš ï¸  æ•¸æ“šåº«ç‚ºç©ºï¼ˆå¯èƒ½åˆå§‹åŒ–ä¸­æ–·ï¼‰")
            need_init = True
        else:
            days_covered = (df['timestamp'].max() - df['timestamp'].min()).days
            print(f"  æ•¸æ“šæ¶µè“‹: ç´„ {days_covered} å¤©")
            print(f"  æ™‚é–“ç¯„åœ: {df['timestamp'].min().date()} è‡³ {df['timestamp'].max().date()}")
            
            # å¦‚æœæ•¸æ“šå°‘æ–¼730å¤©ï¼Œæç¤ºè£œå……
            if days_covered < 700:
                print(f"\nâš ï¸  ç¾æœ‰æ•¸æ“šä¸è¶³2å¹´ï¼Œå»ºè­°è£œå……æ­·å²æ•¸æ“š")
                need_init = True
        
        print("\n" + "="*70)
        
        if need_init:
            print("\né¸é …:")
            print("  [1] è£œå……æ­·å²æ•¸æ“š (åˆå§‹åŒ–æ¨¡å¼ï¼Œè€—æ™‚2-3å°æ™‚)")
            print("  [2] è·³éï¼Œé€²å…¥æ¯æ—¥æ›´æ–°æ¨¡å¼ (å¿«é€Ÿï¼Œå¹¾åç§’)")
            print("  [0] é€€å‡º")
            
            choice = input("\nè«‹é¸æ“‡ (0/1/2): ").strip()
            
            if choice == '1':
                confirm = input("ç¢ºèªè£œå……æ­·å²æ•¸æ“š? (yes/no): ").strip().lower()
                if confirm == 'yes':
                    scraper.run_initial_scrape(days=730)
                else:
                    print("å·²å–æ¶ˆï¼Œé€²å…¥æ¯æ—¥æ›´æ–°æ¨¡å¼")
                    scraper.run_full_scrape()
            elif choice == '2':
                scraper.run_full_scrape()
            else:
                print("å·²é€€å‡º")
                exit(0)
        
        else:
            # æ•¸æ“šå·²è¶³å¤ ï¼Œç›´æ¥é€²å…¥æ¯æ—¥æ›´æ–°æ¨¡å¼
            print(f"âœ“ æ•¸æ“šå……è¶³ï¼Œé€²å…¥ã€æ¯æ—¥æ›´æ–°æ¨¡å¼ã€‘")
            print(f"  ç”¨æ™‚: å¹¾ç§’åˆ°å¹¾åç§’")
            print("="*70)
            scraper.run_full_scrape()
